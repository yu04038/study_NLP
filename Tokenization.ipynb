{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Tokenization.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9wo3vO7_tbr","executionInfo":{"status":"ok","timestamp":1630309126360,"user_tz":-540,"elapsed":1965,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"13cf9d8c-bfba-4454-fe3f-f64a177156ec"},"source":["from nltk.tokenize import word_tokenize\n","import nltk\n","\n","nltk.download('punkt')\n","# word_tokenize는 don't를 do, n't로 구별, jone's는 jone, 's로 구별\n","print(word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EiN4M-Uo_tbt","executionInfo":{"status":"ok","timestamp":1630309129907,"user_tz":-540,"elapsed":255,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"db944f29-290b-4e0c-bf7f-2079c6ba305c"},"source":["from nltk.tokenize import WordPunctTokenizer\n","\n","# WordPunctTokenizer는 구두점을 별도로 분류하는 특징을 갖고 있기때문에,  Don't를 Don과 '와 t로 분리하였으며, Jone's를 Jone과 '와 s로 분리\n","print(WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rh49qiA2_tbv","executionInfo":{"status":"ok","timestamp":1630309419969,"user_tz":-540,"elapsed":284,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"704a5b80-a779-4e74-a458-f8aec09db7e9"},"source":["from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","\n","# 기본적으로 모든 알파벳을 소문자로 바꾸면서 마침표나 컴마, 느낌표 등의 구두점을 제거한다. 하지만 don't나 jone's의 경우 아포스트로피는 그대로\n","print(text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YaNQfHpSGlBD"},"source":["## 표준 토큰화 방법 중 하나인 Penn Treebank Tokenization\n","**규칙 1. 하이푼으로 구성된 단어는 하나로 유지한다.**    \n","**규칙 2. doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다.**"]},{"cell_type":"code","metadata":{"id":"_v4M-Fgt_tbw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630344626361,"user_tz":-540,"elapsed":2422,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"ff334f8e-f275-46a7-96af-1f0c0f8ce6a8"},"source":["from nltk.tokenize import TreebankWordTokenizer\n","\n","tokenizer = TreebankWordTokenizer()\n","# home-based는 하나의 단어로, doesn't는 does, n't로 분리하였음을 알 수 있다!\n","text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n","print(tokenizer.tokenize(text))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aO3bj1ktHe2G"},"source":["## 문장 토큰화(Sentence Tokenization)\n","단순히 마침표(.)로 문장을 구분짓는다고 가정하면, 문장의 끝이 나오기 전에 이미 마침표가 여러번 등장하는 경우에는 예상치 못한 결과가 나오게 된다."]},{"cell_type":"code","metadata":{"id":"HjtkaSTH_tbw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630344853609,"user_tz":-540,"elapsed":853,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"a3403c58-f5c0-4783-d805-f2a207b8f399"},"source":["from nltk.tokenize import sent_tokenize\n","import nltk\n","\n","nltk.download('punkt')\n","\n","text=\"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n","print(sent_tokenize(text))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8znGevxZ_tbx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630344892700,"user_tz":-540,"elapsed":337,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"b33ee9f4-e583-43de-b4c4-4f9f58ed8b4d"},"source":["# NLTK는 단순히 마침표를 구분자로 하지 않기 때문에, Ph.D.를 문장 내의 단어로 인식하여 성공적으로 인식하였음을 볼 수가 있다.\n","text=\"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n","print(sent_tokenize(text))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wfpJUEB7_tby"},"source":["pip install kss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKS2EDEsIZyH","executionInfo":{"status":"ok","timestamp":1630344990294,"user_tz":-540,"elapsed":9429,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"21cbd91f-e97f-4e48-e78f-a8727b78b252"},"source":["import kss\n","\n","text='딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어려워요. 농담아니에요. 이제 해보면 알걸요?'\n","print(kss.split_sentences(text))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[Korean Sentence Splitter]: Initializing Kss...\n"],"name":"stderr"},{"output_type":"stream","text":["['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어려워요. 농담아니에요.', '이제 해보면 알걸요?']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T2BG2zXbJD2X"},"source":["## 이진 분류기(Binary Classifier)\n","\n","**1. 마침표(.)가 단어의 일부분일 경우. 즉, 마침표가 약어(abbreivation)로 쓰이는 경우**  \n","**2. 마침표(.)가 정말로 문장의 구분자(boundary)일 경우**\n","\n","> 마침표(.)가 어떤 클래스에 속하는지 결정을 위해서는 어떤 마침표가 주로 약어(abbreviation)으로 쓰이는 지 알아야하기 때문에, 이진 분류기 구현에서 약어 사전(abbreviation dictionary)가 유용"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKr2UAelIZ0Z","executionInfo":{"status":"ok","timestamp":1630345507159,"user_tz":-540,"elapsed":4308,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"91c36bb5-f5bb-4555-a6d5-bf7208d1d605"},"source":["# NLTK에서는 영어 코퍼스에 품사 태깅 기능을 지원하고 있다. \n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","import nltk\n","\n","nltk.download('averaged_perceptron_tagger')\n","\n","text=\"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n","print(word_tokenize(text))\n","\n","# PRB: 인칭 대명사 \n","# VBP: 동사\n","# RB: 부사\n","# VBG: 현재부사\n","# IN: 전치사\n","# NNP: 고유 명사\n","# NNS: 복수형 명사\n","# CC: 접속사\n","# DT: 관사\n","x=word_tokenize(text)\n","pos_tag(x)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[('I', 'PRP'),\n"," ('am', 'VBP'),\n"," ('actively', 'RB'),\n"," ('looking', 'VBG'),\n"," ('for', 'IN'),\n"," ('Ph.D.', 'NNP'),\n"," ('students', 'NNS'),\n"," ('.', '.'),\n"," ('and', 'CC'),\n"," ('you', 'PRP'),\n"," ('are', 'VBP'),\n"," ('a', 'DT'),\n"," ('Ph.D.', 'NNP'),\n"," ('student', 'NN'),\n"," ('.', '.')]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"2Fnzj_efIZ2n"},"source":["# 한국어는 KoNLPy(코엔엘파이) 패키지를 사용할 수 있음. \n","## 형태소 분석기로 Okt(Open Korea Text), 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma)가 있다.\n","%%bash\n","apt-get update\n","apt-get install g++ openjdk-8-jdk python-dev python3-dev\n","pip3 install JPype1\n","pip3 install konlpy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHrev5mOIZ5J","executionInfo":{"status":"ok","timestamp":1630346164311,"user_tz":-540,"elapsed":438,"user":{"displayName":"조용진","photoUrl":"","userId":"00339473269787323590"}},"outputId":"36a7a28f-dc32-4364-bf36-6e9765a5fba0"},"source":["from konlpy.tag import Okt  \n","okt=Okt()  \n","print(okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) # 형태소 추출\n","print(okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))  # 품사 태깅(Part-of-speech tagging)\n","print(okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))  # 명사 추출"],"execution_count":26,"outputs":[{"output_type":"stream","text":["['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n","[('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n","['코딩', '당신', '연휴', '여행']\n"],"name":"stdout"}]}]}